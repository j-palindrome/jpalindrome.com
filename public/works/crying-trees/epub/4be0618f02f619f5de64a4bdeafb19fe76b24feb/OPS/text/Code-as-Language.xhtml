<?xml version="1.0" encoding="UTF-8" standalone="no"?>
        <html xmlns="http://www.w3.org/1999/xhtml"
          xmlns:epub="http://www.idpf.org/2007/ops"
          xmlns:ibooks="http://vocabulary.itunes.apple.com/rdf/ibooks/vocabulary-extensions-1.0"
          epub:prefix="ibooks: http://vocabulary.itunes.apple.com/rdf/ibooks/vocabulary-extensions-1.0">
        <head>
          <title></title>
          <meta http-equiv="default-style" content="text/html charset=utf-8"/>
          <meta name="robots" content="index,follow"/>
          <link rel="stylesheet" type="text/css" href="../stylesheets/application.css"/>
        </head>
        <body>
      
<!-- START: section:chapter#code-as-language; _markdown/Code-as-Language.md:4 -->
<section id="code-as-language" epub:type="bodymatter chapter" class="bodymatter chapter">
        <div  class=" spread">
          <div id="code" class="spread__content"><h1>Code as Language &amp; Digital Publishing</h1>

    <div class="figure__small figure__small--landscape">
      <figure id="refdigitizing1">
        <a href="figures-titlepage.xhtml#digitizing1">
          <img src="" alt=""/>
        </a>
      </figure>
    </div></div>
            </div>

            <!-- Empty node required for spread markers -->
                   <div></div>

            
<!-- END: section:exit#code -->
<p>A central framework I adopt here is that coding frameworks themselves contain inherent assumptions, ideologies, and configurations. The content of code becomes especially relevant when producing digital content that is embedded into HTML, JavaScript, and CSS: the source of a project and its natural language is embedded in coding directives.</p>
<h2>Prescriptive vs. Descriptive</h2>
<p>I illuminate the contrast in prescriptive and descriptive, arborescent and rhizomatic, to illuminate the Internet's connection to structures of thought. JavaScript is a language accompanied by a standards organization: the ECMA. The JavaScript standards are something like the Spanish &quot;Academie Real,&quot; which produces dictionaries, grammar conventions, and more. Any language has prescriptive and descriptive usages: the prescriptive being dictionary definitions, and the descriptive being actual speakers of the language. The prescriptive and descriptive are in constant dialogue, with standards changing in response to usage, and usage often governed by standards.</p>
<p>JavaScript has prescriptive and descriptive aspects as well, although these conventions are more technologically embedded than traditional language use: the ECMA standards evolve in response to developer needs, integrating extensions into the core language. Importantly, corporations (read: Google, Apple, and Microsoft) have stakes in JavaScript development, as each browser implements its own JavaScript interpreter. In the history of JavaScript development, browsers faced a difficult time in terms of standards, where Google wanted JavaScript to advance while Microsoft adhered to the older standards.</p>
<p>This contradiction of prescriptive and descriptive connects to the innovation in knowledge systems that the Internet constitutes. I pull on Deleuze and Guattari's concept of the Rhizome in order to illuminate these contradictions.</p>
<p>An older method of indexing stems from taxonomies: for example, the classic Dewey Decimal system. Dewey considered a preconceived categorization of human knowledge, in which contents (most often, print books) grouped themselves into smaller and smaller subsections of that numbering. The index is based on large to small, branching outwards. Deleuze and Guattari refer to this structure as <em>arborescence</em>: a root system which branches outwards from an origin. The arborescent knowledge structure is prescriptive: it proceeds by definitions, a priori.</p>
<p>In contrast, a rhizome is small to large: it is a network. Modeled on the growth structures of grass and underground burrows, the rhizome is flat and pluralistic. Any part of a rhizome can connect to any other part, any node in the network connects to any other. Wikipedia exemplifies a rhizomatic knowledge structure: rather than a line of books visible to the browser, one starts from a search, proceeding in structure to other networks of knowledge. The rhizome is descriptive: structure emerges from connection and possibility.</p>
<h2>The fantasy of the descriptive</h2>
<p>The Rhizome of the Internet offers possibilities for knowledge to proliferate in a generative way: publishers are no longer bound by issues or release dates, and perhaps have more open-access channels to create networks of knowledge. This open structure creates a sort of digital utopianism, a feeling of radical openness.</p>
<p>The paradigm of glitch feminism suggests this radical openness:</p>
<blockquote>
<p>For my body, then, subversion came via digital remix, searching for those sites of experimentation where I could explore my true self, open and ready to be read by those who spoke my language. Online, I sought to become a fugitive from the mainstream, unwilling to accept its limited definition of bodies like my own. (Russell)</p>
</blockquote>
<p>Russell is excited by the possibilities of &quot;language&quot; afforded within the Internet, situating it as a primarily descriptive practice: a &quot;remix&quot; for playing with, and bucking, conventions. The power of remix is located in the networked capabilities of the Internet, the capacity to create connections via a rhizomatic structure that avoids contemporary channels such as the &quot;mainstream.&quot; Russell looks to the bottom-up nature of Internet organization, the emergent capabilities of networks and the proliferation of selves that the Internet affords.</p>
<p>This encapsulates the potential of the Internet to literally generate new forms of language—the language of code serving as a platform for human languages that are more &quot;true,&quot; that are &quot;fugitive.&quot; The Internet becomes a dual space of anonymity and truth, where one avoids the searching gaze of the mainstream and can instead be viewed as one wishes to present oneself. Russell is hopeful that finally, &quot;the Internet still remains a vessel through which a “becoming” can realize itself&quot; (Introduction).</p>
<h2>The Descriptive and information extraction</h2>
<p>The Web is subject to a contradictory discourse: search engines like Google have achieved a monopoly by understanding the very innovations that make the web a pluralistic, utopian idea.</p>
<p>Google realized quickly that the old ways of searching keywords would not work on the Internet. Most keyword-based search tools use a vector-space model which organizes text according to similarity to the search terms, similar to a frequency of word occurrence. However, this method fails to match relevant pages on the unfiltered Internet, as &quot;junk results&quot; can fill up a search by simply matching short search queries exactly. Periodicals and books are assisted by their standard length, but webpages have no such consistency. Additionally, keyword searches can be hacked by standard webpage practices. Google's goal was to resist easy SEO (&quot;search engine optimization&quot;)—so that webpages couldn't hack its algorithms by embedding pervasive keywords or metadata into pages.</p>
<p>The alternative was for Google to understand the Internet through the lenses of the rhizome and fugitivity that Russell and Deleuze &amp; Guattari advocate. Google's success stemmed primarily from its PageRank algorithm, which capitalized upon the &quot;citation (link) graph of the web [...] an important resource that ha[d] largely gone unused in existing web search engines&quot; (Google). Pages no longer needed to simply match search keywords: Google's crawlers marked their place within the emergent network of the Internet, turning the rhizome of hyperlinks back into a hierarchical search sort.</p>
<p>Google no longer needed pages to even conform to standard HTML: it built a custom parser that accomodated the inconsistencies inherent in webpages (&quot;typos in HTML tags to kilobytes of zeros in the middle of a tag, non-ASCII characters, HTML tags nested hundreds deep, and a great variety of other errors that challenge anyone's imagination to come up with equally creative ones&quot;). Instead, by tracing the network of descriptive hyperlinks between pages, Google condensed its information to anchor text and link structure: links, and the commentary on the links. Pages could be opaque and obfuscated: Google would illuminate them.</p>
<h2>Tensions Between Standards</h2>
<p>I bring up the Google search algorithm because it reveals the complexities inherent in digital utopianism, and efforts to use the Internet as a creative space. The anonymity, self-invention, and emergent networks of the Internet lent themselves just as well to the monopoly that Google became, turning into an increasingly standardized Internet in which certain players dominate the search results, and fringe publications have a difficult time ranking high in the lists, getting discovered. The challenges and balances affording digital publishing are clear. So how do we function as radical digital organizations within this situation?</p>
<p>One method is by creating unique platforms that extend the functionality of the standard webpage. This involves hacking default browser behavior using CSS/JavaScript, and potentially creating alternatives to standard HTML that enable more diverse skillsets to interface with the webpage.</p>
<p>To adopt a materialist view of the Web, to build a custom site is to take control of the means of production. This falls short of a Marxist seizure, of a course—the networked, algorithmic Internet falls outside of any political rule, enabling and enacting multinational, corporate power structures—but custom web design is necessary to create anything formally innovative.</p>
<p>Anything innovating the Web is by nature a translation project, as cutting-edge JavaScript has to be translated back to the legacy, more commonly adopted versions. Often, these newer frameworks consider DX, or developer experience, inventing shorthands that make writing code clearer and more fit to the developer's purpose. These shorthands are eventually compiled to standard &quot;vanilla&quot; JavaScript.</p>
</section>
<!-- END: section:#code-as-language -->
<script type="application/javascript" src="../javascripts/application.js"></script><script type="application/javascript">window.bber = window.bber || {}; window.bber.env = 'reader';</script></body></html>